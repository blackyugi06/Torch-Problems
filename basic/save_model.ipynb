{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GK-zD0p20F9"
      },
      "source": [
        "## Problem: Save and Load Your PyTorch Model\n",
        "\n",
        "### Problem Statement\n",
        "You are tasked with saving a trained PyTorch model to a file and later loading it for inference or further training. This process allows you to persist the trained model and use it in different environments without retraining.\n",
        "\n",
        "### Requirements\n",
        "1. **Save the Model**:\n",
        "   - Save the modelâ€™s **state dictionary** (weights) to a file named `model.pth` using `torch.save`.\n",
        "   \n",
        "2. **Load the Model**:\n",
        "   - Load the saved state dictionary into a new model instance using `torch.load`.\n",
        "   - Verify that the loaded model works as expected by performing inference or testing."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solution"
      ],
      "metadata": {
        "id": "wOZVQmg7252q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nxZLBbkw20F_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BTTdohvs20F_"
      },
      "outputs": [],
      "source": [
        "# Define a simple model\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.fc = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Create and train the model\n",
        "torch.manual_seed(42)\n",
        "model = SimpleModel()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "X = torch.rand(100, 1)\n",
        "y = 3 * X + 2 + torch.randn(100, 1) * 0.1\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(X)\n",
        "    loss = criterion(predictions, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3sgAhYBd20F_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f945b99-4387-46bc-9994-8e741a701354"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# TODO: Save the model to a file named \"model.pth\"\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "# TODO: Load the model back from \"model.pth\"\n",
        "loaded_model = SimpleModel()\n",
        "loaded_model.load_state_dict(torch.load(\"model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uWko2wIv20GA",
        "outputId": "40dde3be-739b-47c4-a9ec-cd1186396d6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions after loading: tensor([[3.3646],\n",
            "        [4.2802],\n",
            "        [5.1959]])\n"
          ]
        }
      ],
      "source": [
        "# Verify the model works after loading\n",
        "X_test = torch.tensor([[0.5], [1.0], [1.5]])\n",
        "with torch.no_grad():\n",
        "    predictions = loaded_model(X_test)\n",
        "    print(f\"Predictions after loading: {predictions}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}